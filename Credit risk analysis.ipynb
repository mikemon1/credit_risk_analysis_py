{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding credit risk\n",
    "* Created on: 05/28/2021\n",
    "* Created by: Michael Monahan\n",
    "* Source reference: DataCamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels as sm\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is credit risk?\n",
    "* The possibility that an entity that has borrowed money will not repay it\n",
    "* Calculated risk difference between lending an entity money and a risk-free investment\n",
    "* When an entitiy fails to repay, it is in default\n",
    "* The likelihood that an entity will default is the probability of default(PD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected loss\n",
    "* The dollar amount a firm loses as a reult of a loan default\n",
    "* Three primary components:\n",
    "    * Probability of Default(PD)\n",
    "    * Exposure at Default (EAD) the outstanding loan amount at default\n",
    "    * Loss Given Default (LGD) ratio of loss : recovery of assets at default\n",
    "* Formula for expected loss:  `expected_loss = PD * EAD * LGD`\n",
    "\n",
    "## Types of data used\n",
    "* Two primary types of data used:\n",
    "    * **Application data:** interest rates, FICO, loan amount, loan intent\n",
    "    * **Behavioral data:** employment length, history of default, income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "* Prepared data allows models to train faster\n",
    "* Often positively impacts model performance\n",
    "### Outliers and performance\n",
    "* Possible causes of outliers:\n",
    "    * Entry error\n",
    "    * Technical issues or system failures \n",
    "### Detecting outliers with cross tables\n",
    "* Using cross tables with aggregate functions\n",
    "```python\n",
    "pd.crosstab(cr_loan['person_home_ownership'],cr_loan['loan_status'],\n",
    "            values=cr_loan['loan_int_rate'], aggfunc='mean').round(2)\n",
    "```\n",
    "* Removing outliers using the `.drop()` method within Pandas\n",
    "```python\n",
    "indicies = cr_loan[cr_loan['person_emp_length'] >= 60].index\n",
    "cr_loan.drop(indicies, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "# Do not run\n",
    "\n",
    "# Create the cross table for loan status, home ownership, and the max employment length\n",
    "print(pd.crosstab(cr_loan['loan_status'],cr_loan['person_home_ownership'],\n",
    "                  values=cr_loan['person_emp_length'], aggfunc='max'))\n",
    "\n",
    "# Create an array of indices where employment length is greater than 60\n",
    "indices = cr_loan[cr_loan['person_emp_length'] > 60].index\n",
    "\n",
    "# Drop the records from the data based on the indices and create a new dataframe\n",
    "cr_loan_new = cr_loan.drop(indices)\n",
    "\n",
    "# Create the cross table from earlier and include minimum employment length\n",
    "print(pd.crosstab(cr_loan_new['loan_status'],cr_loan_new['person_home_ownership'],\n",
    "                  values=cr_loan_new['person_emp_length'], aggfunc=['min','max']))\n",
    "\n",
    "# Use Pandas to drop the record from the data frame and create a new one\n",
    "cr_loan_new = cr_loan.drop(cr_loan[cr_loan['person_age'] > 100].index)\n",
    "\n",
    "# Create a scatter plot of age and interest rate\n",
    "colors = [\"blue\",\"red\"]\n",
    "plt.scatter(cr_loan_new['person_age'], cr_loan_new['loan_int_rate'],\n",
    "            c = cr_loan_new['loan_status'],\n",
    "            cmap = matplotlib.colors.ListedColormap(colors),\n",
    "            alpha=0.5)\n",
    "plt.xlabel(\"Person Age\")\n",
    "plt.ylabel(\"Loan Interest Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk with missing data in loan data\n",
    "### How to handle missing data?\n",
    "* Generally there are three ways to handle missing data\n",
    "1. Impute values where data is missing\n",
    "2. Remove rows containing missing values\n",
    "3. Leave the rows with missing data unchanged\n",
    "* Understanding the data determines the course of action\n",
    "### Finding missing data \n",
    "* Null values are easily found using the `isnull()` function\n",
    "* Null records can be easily counted with the `sum()` function\n",
    "* `.any()` method checks all columns\n",
    "```python\n",
    "null_columns = cr_loan.columns[cr_loan.isnull().any()]\n",
    "cr_loan[null_columns].isnull().sum()\n",
    "```\n",
    "### Replacing missing data \n",
    "* Replace missing data using methods like `.fillna()` with aggregate functions and methods\n",
    "```python\n",
    "cr_loan['loan_int_rate'].fillna((cr_loan['loan_int_rate'].mean()),inplace=True)\n",
    "```\n",
    "### Dropping missing data \n",
    "* Uses indices to identify records the same as with outliers\n",
    "* Remove the records entirely using the `.drop()` method\n",
    "```python\n",
    "indices = cr_loan[cr_loan['person_emp_length'].isnull()].index\n",
    "cr_loan.drop(indices, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Print a null value column array\n",
    "print(cr_loan.columns[cr_loan.isnull().any()])\n",
    "\n",
    "# Print the top five rows with nulls for employment length\n",
    "print(cr_loan[cr_loan['person_emp_length'].isnull()].head())\n",
    "\n",
    "# Impute the null values with the median value for all employment lengths\n",
    "cr_loan['person_emp_length'].fillna((cr_loan['person_emp_length'].median()), inplace=True)\n",
    "\n",
    "# Create a histogram of employment length\n",
    "n, bins, patches = plt.hist(cr_loan['person_emp_length'], bins='auto', color='blue')\n",
    "plt.xlabel(\"Person Employment Length\")\n",
    "plt.show()\n",
    "\n",
    "# Print the number of nulls\n",
    "print(cr_loan['loan_int_rate'].isnull().sum())\n",
    "\n",
    "# Store the array on indices\n",
    "indices = cr_loan[cr_loan['loan_int_rate'].isnull()].index\n",
    "\n",
    "# Save the new data without missing data\n",
    "cr_loan_clean = cr_loan.drop(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression for probability of default\n",
    "### Predicting probabilites\n",
    "* Probabilities of default as an outcome from machine learning\n",
    "    * Learn from data in columns (features)\n",
    "* Classification models (default, non-default)\n",
    "* Two most common models:\n",
    "    * Logistic regression\n",
    "    * Decision tree\n",
    "\n",
    "### Logistic regression\n",
    "* Similar to linear regression, but only produces values between `0` and `1`\n",
    "* Logistic regression available within scikit-learn package\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "```\n",
    "* Called as a function with or without parameters\n",
    "```python\n",
    "clf_logistic = LogisticRegression(solver='lbfgs')\n",
    "```\n",
    "* Uses the `.fit()` method to train\n",
    "```python\n",
    "clf_logistic.fit(training_columns, np.ravel(training_labels))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets (60 - 40 rule)\n",
    "### Creating the training and test sets\n",
    "* Sperate the data into training columns and labels\n",
    "```python\n",
    "X = cr_loan.drop('loan_status', axis  = 1)\n",
    "y = cr_loan[['loan_status']]\n",
    "```\n",
    "* Use `train_test_split()` function in the sci-kit learn\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=123)\n",
    "```\n",
    "* `test_size`: a percentage of data for test set\n",
    "* `random_state`: a random seed value for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Create the X and y data sets\n",
    "X = cr_loan_clean[['loan_int_rate']]\n",
    "y = cr_loan_clean[['loan_status']]\n",
    "\n",
    "# Create and fit a logistic regression model\n",
    "clf_logistic_single = LogisticRegression(solver='lbfgs')\n",
    "clf_logistic_single.fit(X, np.ravel(y))\n",
    "\n",
    "# Print the parameters of the model\n",
    "print(clf_logistic_single.get_params())\n",
    "\n",
    "# Print the intercept of the model\n",
    "print(clf_logistic_single.intercept_)\n",
    "\n",
    "\n",
    "# Create X data for the model\n",
    "X_multi = cr_loan_clean[['loan_int_rate','person_emp_length']]\n",
    "\n",
    "# Create a set of y data for training\n",
    "y = cr_loan_clean[['loan_status']]\n",
    "\n",
    "# Create and train a new logistic regression\n",
    "clf_logistic_multi = LogisticRegression(solver='lbfgs').fit(X_multi, np.ravel(y))\n",
    "\n",
    "# Print the intercept of the model\n",
    "print(clf_logistic_multi.intercept_)\n",
    "\n",
    "# Create the X and y data sets\n",
    "X = cr_loan_clean[['loan_int_rate','person_emp_length','person_income']]\n",
    "y = cr_loan_clean[['loan_status']]\n",
    "\n",
    "# Use test_train_split to create the training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "clf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Print the models coefficients\n",
    "print(clf_logistic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the probability of default\n",
    "* Using one-hot encoding to convert non-numeric variable to an int using `get_dummies()` in Pandas\n",
    "```python\n",
    "# Seperate the numeric columns\n",
    "cred_num = cr_loan.select_dtypes(exclude=['object'])\n",
    "# Seperate non-numeric columns\n",
    "cred_cat = cr_loan.select_dtypes(include=['object'])\n",
    "# One-hot encode the non-numeric columns only\n",
    "cred_cat_onehot = pd.get_dummies(cred_cat)\n",
    "# Union the numeric columns with the one-hot encoded columns\n",
    "cr_loan = pd.concat([cred_num,cred_cat_onehot], axis = 1)\n",
    "```\n",
    "* Use the `predict_proba()` method in scikit-learn\n",
    "```python\n",
    "# Train the model\n",
    "clf_logistic.fit(X_train, np.ravel(y_train))\n",
    "# Predict using the model\n",
    "clf_logistic.predict_proba(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit model performance\n",
    "### Model accuracy scoring\n",
    "* Calculate accuracy\n",
    "    * Accuracy = Number of correct predictions / number of predicitons\n",
    "* Use the `.score()` method from scikit-learn\n",
    "```python \n",
    "# Check the accuracy against the test data \n",
    "clf_logistic.score(X_test,y_yest)\n",
    "```\n",
    "### ROC curve charts\n",
    "* Receiver Operating Characteristic curve\n",
    "    * Plots true positive rates (sensitivity) against false positive rate (fall-out)\n",
    "```python\n",
    "fallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\n",
    "plt.plot(fallout, sensitivity, color= 'darkorange')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Create a dataframe for the probabilities of default\n",
    "preds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\n",
    "\n",
    "# Reassign loan status based on the threshold\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.50 else 0)\n",
    "\n",
    "# Print the row counts for each loan status\n",
    "print(preds_df['loan_status'].value_counts())\n",
    "\n",
    "# Print the classification report\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(classification_report(y_test, preds_df['loan_status'], target_names=target_names))\n",
    "\n",
    "# Print all the non-average values from the report\n",
    "print(precision_recall_fscore_support(y_test,preds_df['loan_status']))\n",
    "\n",
    "# Print the first two numbers from the report\n",
    "print(precision_recall_fscore_support(y_test,preds_df['loan_status'])[2])\n",
    "\n",
    "# Create predictions and store them in a variable\n",
    "preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Print the accuracy score the model\n",
    "print(clf_logistic.score(X_test, y_test))\n",
    "\n",
    "# Plot the ROC curve of the probabilities of default\n",
    "prob_default = preds[:, 1]\n",
    "fallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\n",
    "plt.plot(fallout, sensitivity, color = 'darkorange')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Compute the AUC and store it in a variable\n",
    "auc = roc_auc_score(y_test, prob_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model discrimination and impact\n",
    "### Confusion matrices\n",
    "* Shows the number of correct and incorrect predictions for each `loan_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Set the threshold for defaults to 0.5\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test,preds_df['loan_status']))\n",
    "\n",
    "# Set the threshold for defaults to 0.5\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.4 else 0)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test,preds_df['loan_status']))\n",
    "\n",
    "# Reassign the values of loan status based on the new threshold\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.4 else 0)\n",
    "\n",
    "# Store the number of loan defaults from the prediction data\n",
    "num_defaults = preds_df['loan_status'].value_counts()[1]\n",
    "\n",
    "# Store the default recall from the classification report\n",
    "default_recall = precision_recall_fscore_support(y_test,preds_df['loan_status'])[1][1]\n",
    "\n",
    "# Calculate the estimated impact of the new default recall rate\n",
    "print(num_defaults * avg_loan_amnt * (1 - default_recall))\n",
    "\n",
    "plt.plot(thresh,def_recalls)\n",
    "plt.plot(thresh,nondef_recalls)\n",
    "plt.plot(thresh,accs)\n",
    "plt.xlabel(\"Probability Threshold\")\n",
    "plt.xticks(ticks)\n",
    "plt.legend([\"Default Recall\",\"Non-default Recall\",\"Model Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted trees with XGBoost\n",
    "### Decision trees\n",
    "* Creates predictions similar to logistic regression\n",
    "* Not structured like a regression model\n",
    "\n",
    "### A forest of decision trees\n",
    "* XGBoost uses many simplistic trees (ensemble)\n",
    "* Each tree will be slightly better than a coin toss\n",
    "* Creating and training trees\n",
    "    * part of the `xgboost` package in Python, called `xgb`\n",
    "    * trains with `.fit()` just like the logistic regression model\n",
    "```python\n",
    "# Examples\n",
    "# Create a logistic regression model\n",
    "clf_logistic = LogisticRegression()\n",
    "# Train the logistic regression\n",
    "clf_logistic.fit(X_train, np.ravel(y_train))\n",
    "# Create a gradient boosted tree model\n",
    "clf_gbt = xgb.XGBClassifier()\n",
    "# Train the gradient boosted tree\n",
    "clf_xgb.fit(X_train, np.ravel(y_train))\n",
    "```\n",
    "\n",
    "### Hyperparameters of gradient boosted trees\n",
    "* **Hyperparameters:** model parameters(settings) that cannot be learned from the data\n",
    "* Some common hyperparameters for gradient boosted trees:\n",
    "    * `learning rate`: smaller values make each step more conservative\n",
    "    * `max_depth`: sets how deep each tree can go, larger indicates more complexity\n",
    "```python\n",
    "xgb.XGBClassifier(learning_rate = 0.2,\n",
    "                  max_depth = 4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Train a model\n",
    "import xgboost as xgb\n",
    "clf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict with a model\n",
    "gbt_preds = clf_gbt.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "preds_df = pd.DataFrame(gbt_preds[:,1][0:5], columns = ['prob_default'])\n",
    "true_df = y_test.head()\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))\n",
    "\n",
    "# Print the first five rows of the portfolio data frame\n",
    "print(portfolio.head())\n",
    "\n",
    "# Create expected loss columns for each model using the formula\n",
    "portfolio['gbt_expected_loss'] = portfolio['gbt_prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "portfolio['lr_expected_loss'] = portfolio['lr_prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "\n",
    "# Print the sum of the expected loss for lr\n",
    "print('LR expected loss: ', np.sum(portfolio['lr_expected_loss']))\n",
    "\n",
    "# Print the sum of the expected loss for gbt\n",
    "print('GBT expected loss: ', np.sum(portfolio['gbt_expected_loss']))\n",
    "\n",
    "# Predict the labels for loan status\n",
    "gbt_preds = clf_gbt.predict(X_test)\n",
    "\n",
    "# Check the values created by the predict method\n",
    "print(gbt_preds)\n",
    "\n",
    "# Print the classification report of the model\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(classification_report(y_test, gbt_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection for credit risk\n",
    "### Column importance \n",
    "* Use the `.get_booster()` and `.get_score()` methods\n",
    "    * **Weight:** the number of times a column appears in all trees\n",
    "```python\n",
    "# Train the model\n",
    "clf_gbt.fit(X_train, np.ravel(y_train))\n",
    "# Print the feature importances\n",
    "clf_gbt.get_booster().get_score(importance_type = 'weight')\n",
    "```\n",
    "### Plotting column importances\n",
    "* Use the `plot_importance()` function\n",
    "```python\n",
    "xgb.plot_importance(clf_gbt, importance_type = 'weight')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation for credit models\n",
    "### Cross validation basics\n",
    "* Used to train and test the model in a way that simulates using the model on new data\n",
    "* Segments the training data into different pieces to estimate futurre performance\n",
    "* Uses `DMatrix`, an internal structure optimized for `XGBoost`\n",
    "* Early stopping tells cross validation to stop after a scoring metric has not improved after x number of iterations\n",
    "### How it works\n",
    "* Processes parts of training data (folds) and tests against the unused training data \n",
    "* Final testing against the actual test set\n",
    "\n",
    "### Setting up cross validation with XGBoost\n",
    "```python\n",
    "# Set the number of folds\n",
    "n_folds = 2\n",
    "# Set the early stopping number\n",
    "early_stop = 5\n",
    "# Set any specific parameters for cross validation \n",
    "params = {'objective':'binary:logistic',\n",
    "          'seed':99, 'eval_metric':'auc'}\n",
    "```\n",
    "* `'binary':'logistic'` is used to specify classification for `loan_status`\n",
    "* `'eval_metric':'auc'` tells XGBoost to score the model's performance on AUC\n",
    "\n",
    "### Using cross validation with XGBoost\n",
    "```python\n",
    "# Restructure the train data for xgboost\n",
    "DTrain = xgb.DMatrix(X_train, label = y_train)\n",
    "# Perform cross validation\n",
    "xgb.cv(params, DTrain, num_boost_round = 5, nfold= n_folds,\n",
    "       early_stopping_rounds= early_stop)\n",
    "```\n",
    "\n",
    "### Cross validation scoring\n",
    "* Uses cross validation and scoring metrics with `cross_val_score` function in scikit-learn\n",
    "```python\n",
    "# Import the module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Create a gbt model\n",
    "xg = xgb.XGBClassifier(learning_rate = 0.4, max_depth = 10)\n",
    "# Use cross validation and accuracy scores five consecutive times\n",
    "cross_val_score(gbt, X_train, y_train, cv = 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Create a gradient boosted tree model using two hyperparameters\n",
    "gbt = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7)\n",
    "\n",
    "# Calculate the cross validation scores for 4 folds\n",
    "cv_scores = cross_val_score(gbt, X_train, np.ravel(y_train), cv = 4)\n",
    "\n",
    "# Print the cross validation scores\n",
    "print(cv_scores)\n",
    "\n",
    "# Print the average accuracy and standard deviation of the scores\n",
    "print(\"Average accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(),\n",
    "                                              cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class imbalances\n",
    "### Model loss function\n",
    "* Gradient boosted trees in `xgboost` use s loss function of log-loss\n",
    "### Causes of imbalance\n",
    "* Data problems:\n",
    "    * Credit data was not sampled correctly\n",
    "    * Data storage problems\n",
    "* Business processes:\n",
    "    * Measures already in place to not accept probable defaults\n",
    "    * Probable defaults are quickly sold to other firms\n",
    "* Behavioral factors:\n",
    "    * Normally, people do not default on their loans\n",
    "    * The less often they default, the higher their credit rating\n",
    "    \n",
    "### Undersampling to equalize class proportions\n",
    "* Training and testing sets must be put back together\n",
    "* Create two new sets based on actual `loan_status`\n",
    "```python\n",
    "# Concat the training sets\n",
    "X_y_train = pd.concat([X_train.reset_index(drop=True),\n",
    "                       y_train.reset_index(drop=True)], axis = 1)\n",
    "# Get counts of defaults and non-defaults\n",
    "count_nondefault, count_default = X_y_train['loan_status'].value.counts()\n",
    "# Seperate nondefaults and defaults\n",
    "nondefaults = X_y_train[X_y_train['loan_status']==0]\n",
    "defaults = X_y_train[X_y_train['loan_status']==1]\n",
    "```\n",
    "* Randomly sample data set of non-ddefaults\n",
    "* Concatenate with data set of defaults\n",
    "```python\n",
    "# Undersample the non-defaults using sample() in pandas\n",
    "nondefaults_under = nondefaults.sample(count_default)\n",
    "# Concat the undersampled non-defaults with the defaults\n",
    "X_y_train_under = pd.concat([nondefaults_under.reset_index(drop=True),\n",
    "                             defaults.reset_index(drop=True)],axis = 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "# Do not run\n",
    "\n",
    "# Create data sets for defaults and non-defaults\n",
    "nondefaults = X_y_train[X_y_train['loan_status'] == 0]\n",
    "defaults = X_y_train[X_y_train['loan_status'] == 1]\n",
    "\n",
    "# Undersample the non-defaults\n",
    "nondefaults_under = nondefaults.sample(count_default)\n",
    "\n",
    "# Concatenate the undersampled nondefaults with defaults\n",
    "X_y_train_under = pd.concat([nondefaults_under.reset_index(drop = True),\n",
    "                             defaults.reset_index(drop = True)], axis = 0)\n",
    "\n",
    "# Print the value counts for loan status\n",
    "print(X_y_train_under['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and implementation\n",
    "### Comparing classification reports\n",
    "* Create reports with `classification_report()` and compare\n",
    "* ROC and AUC analysis\n",
    "    * models with better performance will have more lift\n",
    "    * more lift suggests the AUC score is higher\n",
    "    \n",
    "### Calculating model calibration\n",
    "* Shows precentage of true defaults for each predicted probability\n",
    "* a line plot of the results of the `calibration_curve()`\n",
    "```python\n",
    "from sklearn.calibration import calibration_curve\n",
    "calibration_curve(y_test, probabilities_of_default, n_bins = 5)\n",
    "```\n",
    "* Plotting calibration curves\n",
    "```python \n",
    "plt.plot(mean_predicted_value, fraction_of_positives, label = '%s' % \"Example Model\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eample \n",
    "# Do not run\n",
    "\n",
    "# Print the logistic regression classification report\n",
    "target_names = ['Non-Default', 'Default']\n",
    "print(classification_report(y_test, preds_df_lr['loan_status'], target_names=target_names))\n",
    "\n",
    "# Print the gradient boosted tree classification report\n",
    "print(classification_report(y_test, preds_df_gbt['loan_status'], target_names=target_names))\n",
    "\n",
    "# Print the default F-1 scores for the logistic regression\n",
    "print(precision_recall_fscore_support(y_test,preds_df_lr['loan_status'], average = 'macro')[2])\n",
    "\n",
    "# Print the default F-1 scores for the gradient boosted tree\n",
    "print(precision_recall_fscore_support(y_test,preds_df_gbt['loan_status'], average = 'macro')[2])\n",
    "\n",
    "# ROC chart components\n",
    "fallout_lr, sensitivity_lr, thresholds_lr = roc_curve(y_test, clf_logistic_preds)\n",
    "fallout_gbt, sensitivity_gbt, thresholds_gbt = roc_curve(y_test, clf_gbt_preds)\n",
    "\n",
    "# ROC Chart with both\n",
    "plt.plot(fallout_lr, sensitivity_lr, color = 'blue', label='%s' % 'Logistic Regression')\n",
    "plt.plot(fallout_gbt, sensitivity_gbt, color = 'green', label='%s' % 'GBT')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='%s' % 'Random Prediction')\n",
    "plt.title(\"ROC Chart for LR and GBT on the Probability of Default\")\n",
    "plt.xlabel('Fall-out')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the logistic regression AUC with formatting\n",
    "print(\"Logistic Regression AUC Score: %0.2f\" % roc_auc_score(y_test, clf_logistic_preds))\n",
    "\n",
    "# Print the gradient boosted tree AUC with formatting\n",
    "print(\"Gradient Boosted Tree AUC Score: %0.2f\" % roc_auc_score(y_test, clf_gbt_preds))\n",
    "\n",
    "# Create the calibration curve plot with the guideline\n",
    "plt.plot([0, 1], [0, 1], 'k:', label='Perfectly calibrated') \n",
    "plt.plot(mean_pred_val_lr, frac_of_pos_lr,\n",
    "         's-', label='%s' % 'Logistic Regression')\n",
    "\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.xlabel('Average Predicted Probability')\n",
    "plt.legend()\n",
    "plt.title('Calibration Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit acceptance rates\n",
    "* Can use model predictions to set better loan acceptance thresholds\n",
    "* The goal is deny probable defaults for all new loans\n",
    "* **Acceptance rate:** what percentage of *new loans* are accepted to keep the number of defaults in a portfolio low\n",
    "    * Accepted loans which are defaults have an impact similar to false negatives\n",
    "\n",
    "* Calculate the threshold value for an 85% acceptance rate\n",
    "```python\n",
    "# Compute the threshold for 85% acceptance\n",
    "threshold = np.quantile(prob_default, 0.85)\n",
    "# Compute the quantile on the probabilities of default\n",
    "preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > {threshold} else 0)\n",
    "```\n",
    "### Bad rate \n",
    "* Even with a calculated threshold, some of the accepted loans will be defaults\n",
    "* These are loans with `prob_default` values where the model is not well calibrated\n",
    "  Bad Rate = Accepted Defaults / Total Accepted Loans\n",
    "```python\n",
    "# Calculate the bad rate\n",
    "np.sum(accepted_loans['true_loan_status']) / accepted_loans['true_loan_status'].count()\n",
    "```\n",
    "* If non-default is `0`, and default is `1` than the `sum()` is the count of defaults\n",
    "* The `.count()` of a single column is the same as the row count for the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Check the statistics of the probabilities of default\n",
    "print(test_pred_df['prob_default'].describe())\n",
    "\n",
    "# Calculate the threshold for a 85% acceptance rate\n",
    "threshold_85 = np.quantile(test_pred_df['prob_default'], 0.85)\n",
    "\n",
    "# Apply acceptance rate threshold\n",
    "test_pred_df['pred_loan_status'] = test_pred_df['prob_default'].apply(lambda x: 1 if x > threshold_85 else 0)\n",
    "\n",
    "# Print the counts of loan status after the threshold\n",
    "print(test_pred_df['pred_loan_status'].value_counts())\n",
    "\n",
    "# Plot the predicted probabilities of default\n",
    "plt.hist(clf_gbt_preds, color = 'blue', bins = 40)\n",
    "\n",
    "# Calculate the threshold with quantile\n",
    "threshold = np.quantile(clf_gbt_preds, 0.85)\n",
    "\n",
    "# Add a reference line to the plot for the threshold\n",
    "plt.hist(x = clf_gbt_preds, color = 'red')\n",
    "plt.axvline(threshold)\n",
    "plt.show()\n",
    "\n",
    "# Print the top 5 rows of the new data frame\n",
    "print(test_pred_df.head())\n",
    "\n",
    "# Create a subset of only accepted loans\n",
    "accepted_loans = test_pred_df[test_pred_df['pred_loan_status'] == 0]\n",
    "\n",
    "# Calculate the bad rate\n",
    "print(np.sum(accepted_loans['true_loan_status']) / accepted_loans['true_loan_status'].count())\n",
    "\n",
    "# Print the statistics of the loan amount column\n",
    "print(test_pred_df['loan_amnt'].describe())\n",
    "\n",
    "# Store the average loan amount\n",
    "avg_loan = np.mean(test_pred_df['loan_amnt'])\n",
    "\n",
    "# Set the formatting for currency, and print the cross tab\n",
    "pd.options.display.float_format = '${:,.2f}'.format\n",
    "print(pd.crosstab(test_pred_df['true_loan_status'],\n",
    "                 test_pred_df['pred_loan_status_15']).apply(lambda x: x * avg_loan, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit strategy and minimum expected loss\n",
    "### Selecting acceptance rates\n",
    "* Acceptance rates are not fixed\n",
    "* Two options to test different rates:\n",
    "    * Calculate the threshold, bad rate and losses manually\n",
    "    * Automatically create a table of these values and select an acceptance rate\n",
    "* The table of all possible values is called a strategy table\n",
    "\n",
    "### Setting up the strategy table \n",
    "* Set up arrays or lists to store each value\n",
    "```python\n",
    "# Set all the acceptance rates to test\n",
    "accept_rates = [1.0,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05]\n",
    "# Create lists to store thresholds and bad rates\n",
    "thresholds = []\n",
    "bad_rates = []\n",
    "```\n",
    "```python\n",
    "for rate in accept_rates:\n",
    "    # Calculate threshold\n",
    "    threshold = np.quantile(preds_df['prob_default'],rate).round(3)\n",
    "    # Store threshold value in a list\n",
    "    thresholds.append(np.quantile(preds_df['prob_default'],rate).round(3))\n",
    "    # Apply the threshold to reassign loan status\n",
    "    test_pred_df['pred_loan_status'] = \\\n",
    "    test_pred_df['prob_default'].apply(lambda x: 1 if threshold else 0)\n",
    "    # Create accepted loans set of predicted non-defaults\n",
    "    accepted_loans = test_pred_df[test_pred_df['pred_loan_status'] == 0]\n",
    "    # Calculate and store the bad rate\n",
    "    bad_rates.append(np.sum((accepted_loans['true_loan_status'])\n",
    "                            / accepted_loans['true_loan_status'].count()).round(3))\n",
    "```\n",
    "```python\n",
    "strat_df = pd.DataFrame(zip(accept_rates, thresholds, bad_rates),\n",
    "                        columns = ['Acceptance Rate','Threshold','Bad Rate'])\n",
    "```\n",
    "\n",
    "### Total expected loss\n",
    "* How much one expects to lose on the defaults in the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Do not run\n",
    "\n",
    "# Print the first five rows of the data frame\n",
    "print(test_pred_df.head())\n",
    "\n",
    "# Calculate the bank's expected loss and assign it to a new column\n",
    "test_pred_df['expected_loss'] = test_pred_df['prob_default'] * test_pred_df['loss_given_default'] * test_pred_df['loan_amnt']\n",
    "\n",
    "# Calculate the total expected loss to two decimal places\n",
    "tot_exp_loss = round(np.sum(test_pred_df['expected_loss']),2)\n",
    "\n",
    "# Print the total expected loss\n",
    "print('Total expected loss: ', '${:,.2f}'.format(tot_exp_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
